{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f435414-5472-4b17-934b-93777e2ad188",
   "metadata": {},
   "source": [
    "# Find Best Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcc4e5b-9e8a-41d7-833d-9c0d6bda0cef",
   "metadata": {},
   "source": [
    "### Step 1: change the following and what i will mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab2b570-1f5d-44b2-ad44-74ac2a5acf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapathway=r\"C:\\Users\\wingt\\Downloads\\S11_along_BD_205.csv\"\n",
    "xstart=3            #column of xstart\n",
    "xstop=5            #column of xend\n",
    "ystart=6           #column of ystart\n",
    "yname='Stress'      # name of the ultimate output array\n",
    "yparameter='Position'       #position here but it will be what is the parameter to be tuned\n",
    "xcolumn=['Travel_length', 'Welding_speed', 'Net_energy_input'] #name of inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf20b3-1f35-4e60-8a72-8d1ae6a9c442",
   "metadata": {},
   "source": [
    "### Step 2 import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f24f54-ae70-460a-be8c-13724240b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "# import ML related libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b65e3-ae89-435b-af42-5735d0a1b1a9",
   "metadata": {},
   "source": [
    "### Step 3: Tune the Optimizer-function\n",
    "a function to tune the hyperparameter of the ANN machine-> optimizer\n",
    "model used is from KerasRegressor\n",
    "Used gridsearch cross validation\n",
    "printing the best optimizer name and the score of this machine\n",
    "printing the mean_test_score, std_test_score, parameter for all the optimizer tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe4a886f-9fde-4b32-9623-e3ccb51f7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_optimizer():\n",
    "    callbacks = [EarlyStopping(monitor='mse', patience=100, verbose=0),]\n",
    "    model = KerasRegressor(build_fn=create_model, nb_epoch=400, batch_size=10, verbose=0) \n",
    "    optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'] # 200 hidden nodes\n",
    "    param_grid = dict(optimizer=optimizer) \n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=8)\n",
    "    grid_result = grid.fit(OP_X_train, OP_Y_train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) \n",
    "    for index, value in enumerate(grid_result.cv_results_['mean_test_score']):\n",
    "        print(\"%f (%f) with: %r\" % (grid_result.cv_results_['mean_test_score'][index], grid_result.cv_results_['std_test_score'][index], grid_result.cv_results_['params'][index]))\n",
    "    print(grid_result.scorer_)\n",
    "    print(pd.DataFrame(grid_result.cv_results_,index=optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960f30b-0024-433a-b949-e115c73310e0",
   "metadata": {},
   "source": [
    "### Step 4: import data + preprocessing(assign x and y values)\n",
    "import the data using pd.read_csv\n",
    "only get columns required\n",
    "assign column names\n",
    "get y data for training as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "383156d4-0b1b-4e58-a1a2-04050456de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(csv_file_name):\n",
    "    '''\n",
    "    used to import dataset and split training and test dataset\n",
    "    csv_file_name is the dateset root\n",
    "    reture traing and test datasets\n",
    "    '''\n",
    "    raw_data = pd.read_csv(csv_file_name,header=None).dropna()\n",
    "    x = raw_data.iloc[:,xstart:(xstop+1)]\n",
    "    #x.columns = xcolumn\n",
    "    y = raw_data.iloc[:,ystart:]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60193e0-0d01-4b42-be77-8e605e8d7149",
   "metadata": {},
   "source": [
    "### Step 5: function for creating a model for tuning optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0fd0870-1d0b-4b17-846d-8e54132f641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(200, activation=tf.nn.leaky_relu, input_shape=(4,)),\n",
    "        keras.layers.Dense(21,activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b37c9-3461-40c4-97cd-c1ae358227a4",
   "metadata": {},
   "source": [
    "### Step 6: Uniform Spaced Sampling\n",
    "Actually this is not required in our case but for this database I will just keep it first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e389e884-c838-45ee-8257-7a4415d0555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniformly_spaced_sampling(y_label, y_label_new, y):\n",
    "    '''\n",
    "    fit and interpolate\n",
    "    '''\n",
    "    f = interpolate.interp1d(y_label, y, kind='linear') # linear interpolation function use first row of y and all of y -> linear interpolate location and y value\n",
    "    ynew=pd.DataFrame(f(y_label_new)) #first row of y (linear distributed) -> linearly interpolate(predict) when in evenly distributed location, what r y\n",
    "    return ynew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3fc473-f9e8-41bb-bef7-9f5f5551103e",
   "metadata": {},
   "source": [
    "### Step 7: assign column names to data set \n",
    "* turn a lot of y columns into one y column only (for ANN2)\n",
    "* However it is not helping us to find the correlations between output and inputs (no equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa92f38-e177-4227-a397-b9edc4145bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_melt(x, y):\n",
    "    '''\n",
    "    Add position as input\n",
    "    input:\n",
    "        x: old input \n",
    "        y: old output\n",
    "    output:\n",
    "        x_new: new input \n",
    "        y_new: new output\n",
    "    '''\n",
    "    y_label_str = [str(x) for x in y_label_new] # make a list of string of y_label_new\n",
    "    dataset = pd.concat([x, y],axis=1, ignore_index=True)\n",
    "    col_names = xcolumn + y_label_str\n",
    "    dataset.columns = col_names\n",
    "    dataset = dataset.melt(id_vars=xcolumn, \n",
    "        var_name=yparameter, \n",
    "        value_name=yname) #for given welding parameter, in a given location, the stress is in this dataset\n",
    "    x_new = dataset.iloc[:, 0:(len(xcolumn)+1)]\n",
    "    y_new = dataset.iloc[:, (len(xcolumn)+1)]\n",
    "    return x_new, y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc98e1e2-4c77-42ba-8f2d-aa99cbec5b04",
   "metadata": {},
   "source": [
    "### Step 8: Define a function getting y(output) label\n",
    "* use y in the csv\n",
    "* the first row of that csv is y_lab\n",
    "* y_lab_new is min to max of y_lab in length of y_lab\n",
    "* this is also not really required for our database (should be idk)\n",
    "* for our database, we should know the name of all the parameters to be calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d966a7f-cc89-4296-a3dd-d2bb2ccff1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_lable(root):\n",
    "    '''\n",
    "    Create an array for uniform interval depth \n",
    "    (Used biased mesh in simulaiton, so the sample point depth is not uniform) \n",
    "    input:\n",
    "        root: file root contains the sample point depth information\n",
    "    outputs:\n",
    "        y_lab: old sample point position array\n",
    "        y_lab_new: new sample point position array\n",
    "    '''\n",
    "    x, y = data_import(root)\n",
    "    y_lab = y.iloc[0, :]\n",
    "    y_lab_new = np.linspace(round(min(y_lab),2), \n",
    "                              round(max(y_lab),2), \n",
    "                              round(len(y_lab),2))\n",
    "    return y_lab, y_lab_new\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08708d5c-00d0-42ab-96fd-a8538a9a8119",
   "metadata": {},
   "source": [
    "### Step 9: Prepocessing function\n",
    "(Bascially just for outputting a standardised form of x and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272701b5-e0a1-4e41-a3b8-0d50ec6e04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OP_pre_processing(model_type,x,y):\n",
    "    '''\n",
    "    Data preprocessing (Uniformly spaced sampling, normalisation, train test split)\n",
    "    inputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)        \n",
    "        x: a dataframe of inputs of the whole dataset\n",
    "        y: a dataframe of outputs of the whole dataset\n",
    "    outputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)\n",
    "        Proc_X_train: Processed Training input\n",
    "        Proc_Y_train: Processed Training output\n",
    "        Proc_X_test: Processed Test input\n",
    "        Y_test: Test output\n",
    "    '''\n",
    "      # uniformly_spaced_sampling\n",
    "    global y_label, y_label_new\n",
    "    y_label, y_label_new = get_y_lable(r'C:\\Users\\wingt\\Downloads\\benchmark_BD1.csv')\n",
    "    y = uniformly_spaced_sampling(y_label, y_label_new, y)\n",
    "    # data reconstruction\n",
    "    if 'ANN2' in model_type:\n",
    "        X_train, Y_train = data_melt(x, y) \n",
    "    # Normalization\n",
    "    global scaler_X, scaler_Y\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_Y = StandardScaler()\n",
    "    scaled_train_X = scaler_X.fit_transform(X_train)\n",
    "    if Y_train.ndim == 1:\n",
    "        Y_train = np.array(Y_train).reshape(-1,1)#column array\n",
    "        scaled_train_Y = scaler_Y.fit_transform(Y_train)\n",
    "        OP_X_train = scaled_train_X\n",
    "        OP_Y_train = scaled_train_Y\n",
    "\n",
    "    return model_type, OP_X_train, OP_Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16200cb-6212-474d-a2fb-be7d67b9a95f",
   "metadata": {},
   "source": [
    "### Step 10: fix random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf2a92d-d8c3-4a8c-880b-6cb97d04439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_tensorflow(seed):\n",
    "    '''\n",
    "    Fix ramdom seed\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Fix ramdom seed\n",
    "warnings.filterwarnings('ignore')\n",
    "seed_tensorflow(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a8c96-c648-4e63-84fc-e338c0f7d4bd",
   "metadata": {},
   "source": [
    "### Step 11: import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf0decb7-1ecf-4470-81f9-a6915a9226a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "x, y = data_import(datapathway)\n",
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee90eb-dce1-4001-a389-49882cc678dc",
   "metadata": {},
   "source": [
    "### Step 12: Optimizer performance maximizing data-preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a8ee49-af8d-46bb-99dc-d57de337addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type, OP_X_train, OP_Y_train= OP_pre_processing('ANN2',x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb432c-f7be-4021-8a31-c65458280ec4",
   "metadata": {},
   "source": [
    "### Step 13: Actual Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f559cee-8b2d-4486-932a-b684e6aa540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               1000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 21)                4221      \n",
      "=================================================================\n",
      "Total params: 5,221\n",
      "Trainable params: 5,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Best: -0.173304 using {'optimizer': 'Adamax'}\n",
      "-0.596253 (0.289181) with: {'optimizer': 'SGD'}\n",
      "-0.233960 (0.142055) with: {'optimizer': 'RMSprop'}\n",
      "-0.921237 (0.424848) with: {'optimizer': 'Adagrad'}\n",
      "-0.984558 (0.425031) with: {'optimizer': 'Adadelta'}\n",
      "-0.223719 (0.113217) with: {'optimizer': 'Adam'}\n",
      "-0.173304 (0.057913) with: {'optimizer': 'Adamax'}\n",
      "-0.222976 (0.123062) with: {'optimizer': 'Nadam'}\n",
      "<function _passthrough_scorer at 0x000002A72936CF70>\n",
      "          mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "SGD            0.591257      0.082115         0.221755        0.014991   \n",
      "RMSprop        0.687674      0.098695         0.164335        0.022028   \n",
      "Adagrad        0.520693      0.037198         0.144580        0.006168   \n",
      "Adadelta       0.545730      0.033415         0.138010        0.015280   \n",
      "Adam           0.587993      0.047107         0.125906        0.009490   \n",
      "Adamax         0.529824      0.031173         0.124941        0.019169   \n",
      "Nadam          0.619261      0.067362         0.082930        0.021877   \n",
      "\n",
      "         param_optimizer                     params  split0_test_score  \\\n",
      "SGD                  SGD       {'optimizer': 'SGD'}          -0.888869   \n",
      "RMSprop          RMSprop   {'optimizer': 'RMSprop'}          -0.467250   \n",
      "Adagrad          Adagrad   {'optimizer': 'Adagrad'}          -1.282084   \n",
      "Adadelta        Adadelta  {'optimizer': 'Adadelta'}          -1.340218   \n",
      "Adam                Adam      {'optimizer': 'Adam'}          -0.410398   \n",
      "Adamax            Adamax    {'optimizer': 'Adamax'}          -0.233161   \n",
      "Nadam              Nadam     {'optimizer': 'Nadam'}          -0.451985   \n",
      "\n",
      "          split1_test_score  split2_test_score  split3_test_score  \\\n",
      "SGD               -0.442264          -0.119425          -0.655274   \n",
      "RMSprop           -0.159583          -0.087165          -0.129616   \n",
      "Adagrad           -0.753392          -0.175189          -1.066267   \n",
      "Adadelta          -0.861100          -0.214438          -1.144531   \n",
      "Adam              -0.141813          -0.088578          -0.195262   \n",
      "Adamax            -0.126351          -0.096210          -0.243991   \n",
      "Nadam             -0.167993          -0.090733          -0.171325   \n",
      "\n",
      "          split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "SGD               -0.875434        -0.596253        0.289181                5  \n",
      "RMSprop           -0.326185        -0.233960        0.142055                4  \n",
      "Adagrad           -1.329252        -0.921237        0.424848                6  \n",
      "Adadelta          -1.362505        -0.984558        0.425031                7  \n",
      "Adam              -0.282545        -0.223719        0.113217                3  \n",
      "Adamax            -0.166805        -0.173304        0.057913                1  \n",
      "Nadam             -0.232842        -0.222976        0.123062                2  \n"
     ]
    }
   ],
   "source": [
    "tune_optimizer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
